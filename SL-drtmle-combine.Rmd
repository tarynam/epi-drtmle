---
title: "Untitled"
author: "Taryn McLaughlin"
date: "10/30/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error=FALSE)
```

```{r Package Requirements, message=FALSE}
##package requirements
pkgs <- c("drtmle","earth","SuperLearner","nloptr", "quadprog","plotmo","plotrix",
          "TeachingDemos","gam","caret","randomForest","arm","RCurl","MASS",
          "tmle","ggplot2","gbm", "dplyr", "drtmle")

# see what packages are currently installed
installed_pacakges <- row.names(installed.packages()) # loop over the needed packages
for(p in pkgs){
    # check if package is installed
    already_installed <- p %in% installed_pacakges
    # if not already installed, install it
    if(!already_installed){ install.packages(p)
    }
    # and load package
    library(p, character.only = TRUE) }

remove(pkgs, installed_pacakges, p, already_installed)
```

```{r Load Data}
dat<-read.csv("/Applications/Old Computer/Epi Project/Data_clean/Kenya_analysis.csv")
dat<-dplyr::select(dat, -X)
for(i in 1:length(dat)){
    n<-length(which(is.na(dat[[i]])))
    print(n)
    }
```
`
```{r Wrappers}
SL.bartMachine #--> test this
SL.mean
SL.ridge
SL.step.forward
SL.step.interaction
SL.rpartPrune

SL.xgboost2<-function(..., maxdepth = 2){
    SL.xgboost(..., max_depth = maxdepth)
}
SL.xgboost4<-function(..., maxdepth = 4){
    SL.xgboost(..., max_depth = maxdepth)
}
SL.xgboost6<-function(..., maxdepth = 6){
    SL.xgboost(..., max_depth = maxdepth)
}

SL.ranger2<-function(..., mtry = 2){
    SL.ranger(..., mtry = mtry)
}
SL.ranger4<-function(..., mtry = 4){
    SL.ranger(..., mtry = mtry)
}
SL.ranger6<-function(..., mtry = 6){
    SL.ranger(..., mtry = mtry)
}

SL.earth.cv <- function(..., nfold = 5){
        SL.earth(..., nfold = nfold)
}

SL.myglm.eachworm <- function(Y, X, newX, ...){
        rhs_glm_formula <- "SM + ascaris + tricuris + hookworm"
        other_variables <- " + age + sex + hiv + viral.load + vl.ind + ControlQFT + ControlQFT.ind + HB + HB.ind + malariaNEG + malariaPOS + pregnantNEG + pregnantPOS + siteJOOTRH + siteKOMBEWA"
        # the rest of the code takes care of things SuperLearner needs
        glm_formula <- paste0("Y ~ ", rhs_glm_formula, other_variables)
        fit.glm <- glm(glm_formula, data = X, family = family)
        pred <- predict(fit.glm, newdata = newX, type = "response")
        fit <- list(object = fit.glm)
        class(fit) <- "SL.glm"
        out <- list(pred = pred, fit = fit)
        return(out)
}
SL.myglm.totalworm <- function(Y, X, newX, ...){
        rhs_glm_formula <- "SM + Number"
        other_variables <- " + age + sex + hiv + viral.load + vl.ind + ControlQFT + ControlQFT.ind + HB + HB.ind + malariaNEG + malariaPOS + pregnantNEG + pregnantPOS + siteJOOTRH + siteKOMBEWA"
        # the rest of the code takes care of things SuperLearner needs
        glm_formula <- paste0("Y ~ ", rhs_glm_formula, other_variables)
        fit.glm <- glm(glm_formula, data = X, family = family)
        pred <- predict(fit.glm, newdata = newX, type = "response")
        fit <- list(object = fit.glm)
        class(fit) <- "SL.glm"
        out <- list(pred = pred, fit = fit)
        return(out)
}

#gam is a glm but flexibly (non-parametrically) models continuous variables
#instead use s(age) in a glm that you define like the other glms --> s stands for splines
#basically doesn't force things to be linear
SL.myspline.eachworm<- function(Y, X, newX, ...){
        rhs_glm_formula <- "SM + ascaris + tricuris + hookworm"
        other_variables <- " + s(age) + sex + hiv + s(viral.load) + vl.ind + s(ControlQFT) + ControlQFT.ind + s(HB) + HB.ind + malariaNEG + malariaPOS + pregnantNEG + pregnantPOS + siteJOOTRH + siteKOMBEWA"
        # the rest of the code takes care of things SuperLearner needs
        glm_formula <- paste0("Y ~ ", rhs_glm_formula, other_variables)
        fit.glm <- glm(glm_formula, data = X, family = family)
        pred <- predict(fit.glm, newdata = newX, type = "response")
        fit <- list(object = fit.glm)
        class(fit) <- "SL.glm"
        out <- list(pred = pred, fit = fit)
        return(out)
}   
SL.myspline.totalworm<- function(Y, X, newX, ...){
        rhs_glm_formula <- "SM + s(Number)"
        other_variables <- " + s(age) + sex + hiv + s(viral.load) + vl.ind + s(ControlQFT) + ControlQFT.ind + s(HB) + HB.ind + malariaNEG + malariaPOS + pregnantNEG + pregnantPOS + siteJOOTRH + siteKOMBEWA"
        # the rest of the code takes care of things SuperLearner needs
        glm_formula <- paste0("Y ~ ", rhs_glm_formula, other_variables)
        fit.glm <- glm(glm_formula, data = X, family = family)
        pred <- predict(fit.glm, newdata = newX, type = "response")
        fit <- list(object = fit.glm)
        class(fit) <- "SL.glm"
        out <- list(pred = pred, fit = fit)
        return(out)
}

#In case modeling on the total data gives us entirely different results than if we modeled separately on HIV

#Writing a glmnet with all 2 way interactions
SL.glmnet2way<-function (Y, X, newX, family, obsWeights, id, alpha = 1, nfolds = 10, 
                         nlambda = 100, useMin = TRUE, loss = "deviance", ...) 
{
    .SL.require("glmnet") #keep this one
    if (!is.matrix(X)) {
        X <- model.matrix(~-1 + .^2, X) #updated
        newX <- model.matrix(~-1 + .^2, newX) #updated
    }
    fitCV <- glmnet::cv.glmnet(x = X, y = Y, weights = obsWeights, 
                               lambda = NULL, type.measure = loss, nfolds = nfolds, 
                               family = family$family, alpha = alpha, nlambda = nlambda, 
                               ...)
    pred <- predict(fitCV, newx = newX, type = "response", s = ifelse(useMin, 
                                                                      "lambda.min", "lambda.1se"))
    fit <- list(object = fitCV, useMin = useMin)
    class(fit) <- "SL.glmnet2way" #changed this to match the name
    out <- list(pred = pred, fit = fit)
    return(out)
}
#How does this know to pull from the new glmnet and not the old one???
predict.SL.glmnet2way<-function (object, newdata, remove_extra_cols = T, add_missing_cols = T, ...) 
{
    .SL.require("glmnet") #keep this one
    if (!is.matrix(newdata)) {
        newdata <- model.matrix(~-1 + .^2, newdata) #updated
    }
    original_cols = rownames(object$object$glmnet.fit$beta) #This is where I wasn't sure. 
    if (remove_extra_cols) {
        extra_cols = setdiff(colnames(newdata), original_cols)
        if (length(extra_cols) > 0) {
            warning(paste("Removing extra columns in prediction data:", 
                          paste(extra_cols, collapse = ", ")))
            newdata = newdata[, !colnames(newdata) %in% extra_cols, 
                              drop = F]
        }
    }
    if (add_missing_cols) {
        missing_cols = setdiff(original_cols, colnames(newdata))
        if (length(missing_cols) > 0) {
            warning(paste("Adding missing columns in prediction data:", 
                          paste(missing_cols, collapse = ", ")))
            new_cols = matrix(0, nrow = nrow(newdata), ncol = length(missing_cols))
            colnames(new_cols) = missing_cols
            newdata = cbind(newdata, new_cols)
            newdata = newdata[, original_cols]
        }
    }
    pred <- predict(object$object, newx = newdata, type = "response", 
                    s = ifelse(object$useMin, "lambda.min", "lambda.1se"))
    return(pred)
}


SL.stratify.glm <- function(Y, X, newX, stratify_variable = "hiv", ...){
        # subset to folks with stratify variable == 1
        X_strat1 <- X[X[,stratify_variable] == 1, , drop = FALSE]
        # drop stratify variable
        X_strat1 <- X_strat1[ , -which(colnames(X_strat1) == stratify_variable)]
        # same thing for held-out data
        newX_strat1 <- newX[newX[,stratify_variable] == 1, , drop = FALSE]
        newX_strat1 <- newX_strat1[ , -which(colnames(newX_strat1) == stratify_variable)]
        # same thing for outcome
        Y_strat1 <- Y[X[,stratify_variable] == 1]
        glm_strat1 <- glm(Y_strat1 ~ . , data = X_strat1, family = family)
        pred_strat1 <- predict(glm_strat1, newdata = newX_strat1, type = "response")
        
        # now play the same game in folks with stratify variable == 0
        # subset to folks with stratify variable == 0
        X_strat0 <- X[X[,stratify_variable] == 0, , drop = FALSE]
        # drop stratify variable
        X_strat0 <- X_strat0[ , -which(colnames(X_strat0) == stratify_variable)]
        # same thing for held-out data
        newX_strat0 <- newX[newX[,stratify_variable] == 0, , drop = FALSE]
        newX_strat0 <- newX_strat0[ , -which(colnames(newX_strat0) == stratify_variable)]
        # same thing for outcome
        Y_strat0 <- Y[X[,stratify_variable] == 0]
        glm_strat0 <- glm(Y_strat0 ~ . , data = X_strat0, family = family)
        pred_strat0 <- predict(glm_strat0, newdata = newX_strat0, type = "response")
 
        # now wrap up in a way that SuperLearner likes
        fit <- list(object_strat0 = glm_strat0, object_strat1 = glm_strat1, 
                    stratify_variable = stratify_variable)
        class(fit) <- "SL.stratify.glm"
        pred <- rep(NA, nrow(newX))
        pred[newX[,stratify_variable] == 1] <- pred_strat1
        pred[newX[,stratify_variable] == 0] <- pred_strat0
        out <- list(pred = pred, fit = fit)
        return(out)
}
predict.SL.stratify.glm <- function(object, newdata, ...){
        # subset newdata based on stratify variable
        newdata_strat1 <- newdata[newdata[,object$stratify_variable] == 1, , drop = FALSE]
        newdata_strat0 <- newdata[newdata[,object$stratify_variable] == 0, , drop = FALSE]
        pred_strat1 <- predict(object$object_strat1, newdata = newdata_strat1, type = "response")
        pred_strat0 <- predict(object$object_strat0, newdata = newdata_strat0, type = "response")
        pred <- rep(NA, nrow(newdata))
        pred[newdata[,stratify_variable] == 1] <- pred_strat1
        pred[newdata[,stratify_variable] == 0] <- pred_strat0 
        return(pred)
}
```

```{r LTBI no missing data}
# try out BART 
system.time({
try_bart <- SL.bartMachine(Y = dat$ltbi, 
                           X =dplyr::select(dat,-ltbi),
                           newX = dplyr::select(dat,-ltbi),
                           obsWeights = rep(1, length(dat$ltbi)),
                           family = binomial())
})

SL_Q <- SuperLearner(
    # Y is the outcome variable
    Y = dat$ltbi,
    # X is a dataframe of predictor variables, in this casce
    # everything in dat except for TB outcomes
    X = dplyr::select(dat,-ltbi, -hc, -tb), 
    newX = NULL,
    # family set to binomial() for 0/1 outcome
    family = binomial(), 
    # SL.library will be filled more completely later
    SL.library = c("SL.mean", "SL.ridge", "SL.step.forward", "SL.step.interaction", "SL.rpartPrune",
        "SL.xgboost2", 'SL.xgboost4', "SL.xgboost6", "SL.myglm.eachworm", "SL.myglm.totalworm", 
        "SL.ranger2", "SL.ranger4", "SL.ranger6", "SL.myspline.eachworm", "SL.myspline.totalworm", 
        "SL.earth.cv", "SL.glmnet2way", "SL.stratify.glm"),
    # method specifies how the ensembling is done
    # convex combination negative log-likelihood
    method = "method.CC_nloglik",
    # id specifies a unique subject identifier. data only has one row 
    # per subject, so OK to leave as NULL (default)
    id = NULL, 
    # verbose controls the printing of messages of SuperLearner's progress.
    verbose = FALSE, 
    # control contains options related to logistic ensemble (trimLogit) 
    # and whether to save the fit library to look at individual 
    # algorithms later. We will leave as default
    control = list(saveFitLibrary = TRUE, trimLogit = 0.001),
    # cvControl specifies parameters related to cross validation. Of note
    # the default is for V=10-fold cross validation. See ?SuperLearner
    # for more details
    cvControl = list(V = 10L, stratifyCV = FALSE, shuffle = TRUE, 
                     validRows = NULL)
)

SL_g <- SuperLearner(
    # our outcome is now the S. mansoni variable
    Y = dat$SM, 
    # our predictors are all variables except for LTBI and S. mansoni
    X = dplyr::select(dat, -SM, -ltbi),
    # outcome is binary, so let's use family = binomial()
    family = binomial(),
    # and convex combination nnloglikelihood method
    method= "method.CC_nloglik",
    # simple library for now
    SL.library = c("SL.glm","SL.earth", "SL.gam", "SL.gbm", "SL.nnet", "SL.nnls", "SL.polymars",
                   "SL.randomForest", "SL.svm")
)

###Propensity scores aka gn in drtmle

###HIV NEGATIVE

    # since we want to run drtmle on HIV- and HIV+ separately we need a way to
    # only include propensity scores for each group
    include<-rownames(subset(dat, dat$hiv==0))
    
    # get propensity scores where P(A = 1 | W) for all observations
    # by extracting SL.pred values from the superlearner object
    gn <- data.frame(SL_g$SL.pred)
    gn <- subset(gn, rownames(gn) %in% include)
    gn_1 <- as.matrix(gn$SL_g.SL.pred)
    
    # generate gn list (the 10 part indicates the order aka A=1 then A=0)
    gn10 <- list(
        # first entry is P(A = 1 | W)
        gn_1,
        # second entry is P(A = 0 | W) = 1 - P(A = 1 | W)
        (1 - gn_1)
    )
    
    ###Outcome Regressions aka Qn in drtmle
    
    # Again we only want the outcome regressions for the HIV- subset
    data<-dplyr::filter(dat, hiv==0)
    # set up a data frame where everyone has SM=1 or SM=0
    dat1 <- dplyr::select(data,-SM)
    dat1$SM <- 1
    dat0 <- dplyr::select(data, -SM)
    dat0$SM <- 0
    
    # for each SM=0 and SM=1 get OR values for each row of the new data frame
    # using the predict function in the OR model built by super learner (SL_Q)
    Q1n <- predict(SL_Q, newdata=dat1)$pred
    Q0n <- predict(SL_Q, newdata=dat0)$pred
    
    # generate Qn list (the 10 part indicates the order aka A=1 then A=0)
    Qn10 <- list(
      # first entry is predicted values setting A = 1
      Q1n,
      # second entry is predicted values setting A = 0
      Q0n
    )

fit_HIVneg <- drtmle(Y=data$LTBI, A=data$SM, 
                     W=dplyr::select(data, -LTBI, -SM),
                     a_0 = c(1,0), family = binomial(),
                     Qn = Qn10, gn = gn10, 
                     SL_gr = c("SL.earth", "SL.glm"), SL_Qr = c("SL.earth", "SL.glm")
)

####HIV POSITIVE

    # since we want to run drtmle on HIV- and HIV+ separately we need a way to
    # only include propensity scores for each group
    include<-rownames(subset(dat, dat$hiv==1))
    
    # get propensity scores where P(A = 1 | W) for all observations
    # by extracting SL.pred values from the superlearner object
    gn <- data.frame(SL_g$SL.pred)
    gn <- subset(gn, rownames(gn) %in% include)
    gn_1 <- as.matrix(gn$SL_g.SL.pred)
    
    # generate gn list (the 10 part indicates the order aka A=1 then A=0)
    gn10 <- list(
        # first entry is P(A = 1 | W)
        gn_1,
        # second entry is P(A = 0 | W) = 1 - P(A = 1 | W)
        (1 - gn_1)
    )
    
    ###Outcome Regressions aka Qn in drtmle
    
    # Again we only want the outcome regressions for the HIV- subset
    data<-dplyr::filter(dat, hiv==1)
    # set up a data frame where everyone has SM=1 or SM=0
    dat1 <- dplyr::select(data,-SM)
    dat1$SM <- 1
    dat0 <- dplyr::select(data, -SM)
    dat0$SM <- 0
    
    # for each SM=0 and SM=1 get OR values for each row of the new data frame
    # using the predict function in the OR model built by super learner (SL_Q)
    Q1n <- predict(SL_Q, newdata=dat1)$pred
    Q0n <- predict(SL_Q, newdata=dat0)$pred
    
    # generate Qn list (the 10 part indicates the order aka A=1 then A=0)
    Qn10 <- list(
      # first entry is predicted values setting A = 1
      Q1n,
      # second entry is predicted values setting A = 0
      Q0n
    )

fit_HIVpos <- drtmle(Y=data$LTBI, A=data$SM, 
                     W=dplyr::select(data, -LTBI, -SM),
                     a_0 = c(1,0), family = binomial(),
                     Qn = Qn10, gn = gn10, 
                     SL_gr = c("SL.earth", "SL.glm"), SL_Qr = c("SL.earth", "SL.glm")
)

IC_LTBI_HIVN<-fit_LTBI_HIVneg$ic_drtmle$ic
IC_LTBI_HIVP<-fit_LTBI_HIVpos$ic_drtmle$ic
save(my_object, file = "path/to/where/I/want/to/save/it.RData")
```

```{r LTBI missing data, eval = FALSE}
library(dplyr)
library(SuperLearner)
library(drtmle)
y = "LTBI"
# make some of the outcome and treatment variables NA
makeNA<-sample(0:600, 10)
dat[,y][rownames(dat) %in% makeNA]<-NA
makeNA<-sample(0:600, 40)
dat$SM[rownames(dat) %in% makeNA]<-NA
dat$DeltaA <- 1
dat$DeltaA[is.na(dat$SM)] <- 0
dat$DeltaY <- 1
dat$DeltaY[is.na(dat[,y])] <- 0
# For all these Super Learners...
# Outcome is binary, so use family = binomial()
# Ensemble using convex combination nnloglikelihood method

# first regress indicator of missing A on W
SL.LTBI_DeltaA <- SuperLearner(
    # our outcome is whether we observe A or not
    Y = dat$DeltaA, 
    # our predictors are all variables except for LTBI, SM and whether we observed SM/LTBI
    X = dplyr::select(dat, -DeltaA, -DeltaY, -SM, -y),
    family = binomial(),
    method= "method.CC_nloglik",
    SL.library = c("SL.glm","SL.mean")
)

# now regress A on W | DeltaA = 1
SL.LTBI_A <- SuperLearner(
    # our outcome is A (SM in this case)
    Y = dplyr::filter(dat, DeltaA == 1)$SM, ####???
    # our predictors are all variables except for LTBI, SM and whether we observed SM/LTBI
    # for all rows where DeltaA = 1
    X = dplyr::filter(dat, DeltaA == 1)%>%
        dplyr::select(-DeltaA, -DeltaY, -SM, -y),
    # newx so that the SL.pred returns a vector the full length of the data set
    newX = dplyr::select(dat, -DeltaA, -DeltaY, -SM, -y),
    family = binomial(),
    method= "method.CC_nloglik",
    SL.library = c("SL.glm","SL.mean")
)

# now regress DeltaY on A + W | DeltaA = 1 ... pooling over values of A
SL.LTBI_DeltaY <- SuperLearner(
    # our outcome is whether we observe Y or not
    Y = dplyr::filter(dat, DeltaA == 1)$DeltaY, 
    # our predictors are all variables except for LTBI, SM and whether we observed SM/LTBI
    X = dplyr::filter(dat, DeltaA == 1)%>%
        dplyr::select(-DeltaA, -DeltaY, -SM, -y),
    family = binomial(),
    method= "method.CC_nloglik",
    SL.library = c("SL.glm","SL.mean")
)

# lastly regress Y on A + W | DeltaY = 1
SL.LTBI_Q <- SuperLearner(
    Y = dplyr::filter(dat, DeltaY == 1)[,y],
    # our predictors are all variables except for LTBI and whether we observed SM/LTBI
    # for all rows where DeltaY = 1 (aka where we observe Y)
    X = dplyr::filter(dat, DeltaY == 1)%>%
        dplyr::select(-DeltaA, -DeltaY, -y,),####had to take out SM to make it work but SM should be included
    # newx so that the SL.pred returns a vector the full length of the data set --->>
    newX = dplyr::select(dat, -DeltaA, -DeltaY, -y), 
    family = binomial(), 
    SL.library = c("SL.glm","SL.mean"),
    method = "method.CC_nloglik",
    # id specifies a unique subject identifier. data has one row per subject, so OK to leave as NULL
    id = NULL, 
    # verbose controls the printing of messages of SuperLearner's progress.
    verbose = FALSE, 
    # control contains options related to logistic ensemble (trimLogit) 
    # and whether to save the fit library to look at individual 
    # algorithms later. We will leave as default
    control = list(saveFitLibrary = TRUE, trimLogit = 0.001),
    # cvControl specifies parameters related to cross validation. Of note
    # the default is for V=10-fold cross validation.
    cvControl = list(V = 10L, stratifyCV = FALSE, shuffle = TRUE, 
                     validRows = NULL)
)

# get estimated propensity for observing A
ps_DeltaA <- SL.LTBI_DeltaA$SL.pred

# get estimated propensity for A = 1
ps_A1 <- SL.LTBI_A$SL.predict
# propensity for A = 0
ps_A0 <- 1 - ps_A1

# get estimated propensity for observing outcome if A = 1
dat1 <- dplyr::select(dat,-SM) #gets rid of the SM variable so you can
dat1$SM <- 1 #add it back with all values = 1
ps_DeltaY_A1 <- predict(SL.LTBI_DeltaY, newdata=dat1)$pred #then predict on this using the SL output

# get estimated propensity for observing outcome if A = 0 ... same as above but with A = 0
dat0 <- dplyr::select(dat, -SM) 
dat0$SM <- 0
ps_DeltaY_A0 <- predict(SL.LTBI_DeltaY, newdata=dat0)$pred

# propensity for observing A, A =1 and for observing Y given A = 1
gn1 <- data.frame(ps_DeltaA * ps_A1 * ps_DeltaY_A1)
# propensity for observing A, A = 0 and for observing Y given A = 0
gn0 <- data.frame(ps_DeltaA * ps_A0 * ps_DeltaY_A0)


####Combining to run drtmle for HIV-

#Propensity Scores
# since we want to run drtmle on HIV- and HIV+ separately we need a way to
# only include propensity scores for each group
include<-rownames(subset(dat, dat$HIV==0))
gn_1 <- subset(gn1, rownames(gn1) %in% include)
gn_1 <- gn_1$ps_DeltaA...ps_A1...ps_DeltaY_A1
gn_0 <- subset(gn0, rownames(gn0) %in% include)
gn_0 <- gn_0$ps_DeltaA...ps_A0...ps_DeltaY_A0


# now combine all results into a single propensity score list
gn10 <- list(gn_1, gn_0)

# Again we only want the outcome regressions for the HIV- subset
data<-dplyr::filter(dat, HIV==0)
# set up data frames where everyone has SM=1 or SM=0
dat1 <- dplyr::select(data,-SM)
dat1$SM <- 1
dat0 <- dplyr::select(data, -SM)
dat0$SM <- 0

# for each SM=0 and SM=1 get OR values for each row of the new data frame
# using the predict function in the OR model built by super learner (SL_Q)
Q1n <- predict(SL.LTBI_Q, newdata=dat1)$pred
Q0n <- predict(SL.LTBI_Q, newdata=dat0)$pred

# generate Qn list (the 10 part indicates the order aka A=1 then A=0)
Qn10 <- list(
  # first entry is predicted values setting A = 1
  Q1n,
  # second entry is predicted values setting A = 0
  Q0n
)

# pass in this gn to drtmle
fit_LTBI_HIVneg <- drtmle(Y=data[,y], A=data$SM, 
                     W=dplyr::select(data, -LTBI, -SM),
                     a_0 = c(1,0), family = binomial(),
                     Qn = Qn10, gn = gn10, 
                     SL_gr = c("SL.earth", "SL.glm"), SL_Qr = c("SL.earth", "SL.glm")
)

IC_LTBI_HIVN<-fit_LTBI_HIVneg$ic_drtmle$ic

####Combining to run drtmle for HIV+

#Propensity Scores
# since we want to run drtmle on HIV- and HIV+ separately we need a way to
# only include propensity scores for each group
include<-rownames(subset(dat, dat$HIV==1))
gn_1 <- subset(gn1, rownames(gn1) %in% include)
gn_1 <- gn_1$ps_DeltaA...ps_A1...ps_DeltaY_A1
gn_0 <- subset(gn0, rownames(gn0) %in% include)
gn_0 <- gn_0$ps_DeltaA...ps_A0...ps_DeltaY_A0


# now combine all results into a single propensity score list
gn10 <- list(gn_1, gn_0)

# Again we only want the outcome regressions for the HIV- subset
data<-dplyr::filter(dat, HIV==1)
# set up data frames where everyone has SM=1 or SM=0
dat1 <- dplyr::select(data,-SM)
dat1$SM <- 1
dat0 <- dplyr::select(data, -SM)
dat0$SM <- 0

# for each SM=0 and SM=1 get OR values for each row of the new data frame
# using the predict function in the OR model built by super learner (SL_Q)
Q1n <- predict(SL.LTBI_Q, newdata=dat1)$pred
Q0n <- predict(SL.LTBI_Q, newdata=dat0)$pred

# generate Qn list (the 10 part indicates the order aka A=1 then A=0)
Qn10 <- list(
  # first entry is predicted values setting A = 1
  Q1n,
  # second entry is predicted values setting A = 0
  Q0n
)

# pass everything to drtmle
fit_LTBI_HIVpos <- drtmle(Y=data[,y], A=data$SM, 
                     W=dplyr::select(data, -LTBI, -SM),
                     a_0 = c(1,0), family = binomial(),
                     Qn = Qn10, gn = gn10, 
                     SL_gr = c("SL.earth", "SL.glm"), SL_Qr = c("SL.earth", "SL.glm")
)

IC_LTBI_HIVP<-fit_LTBI_HIVpos$ic_drtmle$ic

```

```{r}
#solve(cov(IC)) or ginv if solve breaks
```
